# -*- coding: utf-8 -*-
"""Titanic Passenger survival prediction_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oJggpLkm28Nz4ZkaaB4x_-3MI-91wPcL
"""

import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings ('ignore')

"""# **Load dataset**"""

from google.colab import files
uploaded = files.upload()

"""Read Dataset pandas library"""

df=pd.read_csv('titanic.csv')
# print(df)

"""# **Exploratory Data Analysis  and Preprocessing**

Dataset summary / information
"""

print(df.info())

"""Distribution of a Dataset."""

print(df.describe())

""" Display the first 5 rows of a Dataset"""

print(df.head(5))

""" Display the last 5 rows of a Dataset"""

print(df.tail(5))

"""Display the column names"""

print(df.columns)

"""How many rows & columns"""

print(df.shape)

"""Count the number of duplicate rows"""

print(df.duplicated().sum)

"""Check null values"""

print(df.isnull().sum())

"""Visualizing missing data in a Dataset.**Missingno** is a specialized library"""

import matplotlib.pyplot as plt
import missingno as ms

ms.bar(df,figsize=(7,3), color='red')
plt.title('Missing Values')
plt.show()

"""# ***Preprocessing & Feature Engineering Techniques***

Low Data Cabin columns Droped
"""

df.drop(['Cabin'], axis=1, inplace=True)

print(df.columns)
print(df.shape)

"""Embarked column check unique values"""

print(df['Embarked'].unique())
print(df['Embarked'].value_counts())

"""Embarked column Missing values filling most data 'S'"""

df['Embarked']=df['Embarked'].fillna('S')

"""Age column check unique values"""

print(df['Age'].value_counts())

"""How to fill Age missing value check"""

print("Age mean=",df['Age'].mean())
print("Age median=",df['Age'].median())
print("Age mode=",df['Age'].mode())

"""probably suitable mean, fill missing value to mean"""

df['Age']=df['Age'].fillna(df['Age'].mean())

print(df["Age"].isnull().sum())

ms.bar(df,figsize=(7,3), color='red')
plt.title('Missing Values')
plt.show()

"""Survived column check unique values"""

print(df['Survived'].value_counts())

"""Survived & un Survived total Count Graph"""

import seaborn as sns
sns.countplot(x='Survived', data=df)
plt.title('Survived total Count')
plt.show()

"""Gender values Graph"""

print(df['Sex'].value_counts())

fig,axes = plt.subplots(1,2,figsize=(5,3))
df['Sex'].value_counts().plot(kind='bar', ax=axes[1],color=['Darkred','gray'])
df['Sex'].value_counts().plot(kind='pie', ax=axes[0],autopct = '%0.1f',colormap="Reds")
plt.show()

"""Gender based on survived"""

sns.catplot(x="Sex",hue="Survived", kind="count",data=df,height=3,)
plt.show()

"""passenger class based on survived"""

sns.countplot(x="Pclass", hue="Survived", data=df, palette="Reds",)
plt.show()

"""Drop unnecessary column"""

df.drop(["Name","Ticket","PassengerId"],axis=1,inplace=True)
df.head()

ms.bar(df,figsize=(7,3), color='red')
plt.title('Final view')
plt.show()

"""Encoding Categorical data converted numerical data"""

import sklearn
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()

df['Sex'] = le.fit_transform(df['Sex'])
df['Embarked'] = le.fit_transform(df['Embarked'])

df['Age'] = df['Age'].replace(np.nan, 0)
df['Embarked'] = df['Embarked'].replace(np.nan, 0)

print(df)

"""**Split data into training and testing sets**"""

x=df.drop(["Survived"],axis=1)
y=df["Survived"]

print("IP=",x)
print("OT=",y)

"""Split the Data"""

from sklearn.model_selection import train_test_split, cross_val_score
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=12)

print("DF",df.shape)
print("x_train",x_train.shape)
print("x_test",x_test.shape)
print("y_train",y_train.shape)
print("y_test",y_test.shape)

"""# **Model Training**

**import algorithms and libraries**
"""

from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

models = {
    "Naive Bayes": GaussianNB(),
     "Random Forest": RandomForestClassifier(),
    "Logistic Regression": LogisticRegression()
}

model_performance = {}
#TM = titanic model
for TM, model in models.items():
    # Cross-validation
    cv_scores = cross_val_score(model, x_train, y_train, cv=5, scoring='accuracy')

    #  Train Model
    model.fit(x_train, y_train)
    y_pred = model.predict(x_test)

    # Calculate Accuracy
    acc = accuracy_score(y_test, y_pred)
    model_performance[TM] = acc  # Add this line to populate the dictionary

# Final Report
    print(f"\nModel: {TM}")
    print(f"Cross-Validation Accuracy: {cv_scores.mean():.4f}")
    print(f"Model Accuracy: {acc:.4f}")
    print("Classification Report:")
    print(classification_report(y_test, y_pred))

best_model_name = max(model_performance, key=model_performance.get)
best_model = models[best_model_name]


print(f"Best Model: {best_model_name} with Accuracy: {model_performance[best_model_name]*100:.2f}%")

import pickle
with open('best_model.pkl', 'wb') as file:
    pickle.dump(best_model, file)

print("\nModel saved successfully as 'best_model.pkl'")

from google.colab import files

files.download('best_model.pkl')

